import datetime
import json
from typing import Any, Final

from langchain.chat_models import init_chat_model
from langchain_core.callbacks import get_usage_metadata_callback
from pydantic import BaseModel, Field, create_model

from .utils import get_schema
from ..enums import Node
from ..state import SearchState

FACT_CHECK_INSTRUCTIONS = """
Your goal is to check whether the given information about a {search_type} is grounded, using the provided sources.

The {search_type} you are interested in:
<{search_type}>
{info}
</{search_type}>

The information that your are going to check for factfulness:
<information>
{notes}
</information>

The sources you are going to use:
<sources>
{content}
</sources>

Today's date is:
<today>
{today}
</today>

<Requirements> 
* Every item in the given information should be checked for factfulness.
* If a value for a given field is missing, or filled with a filler value (e.g. "Not Available", "NA", etc), return False for the factfulness value.
* Any given information field can be regarded as fact only if:
    - the information is directly written in the given source, or
    - the information can be generated by combining different pieces of the given source
* If a value for a given field is filled with a masked value (e.g. h***@langchain.com), return False for the factfulness value.
</Requirements> 

<Task>
* Think carefully about the provided sources.
* Think carefully about the provided information, and the fields.
* For each information field, check whether the information field is a fact, according to the source, or not. 
</Task>
"""

class AtomicFactfulness(BaseModel):
    title: str = Field(description="The title of the given information that is checked for factfulness.")
    value: Any = Field(description="The value of the given information that is checked for factfulness.")
    is_fact: bool = Field(description="Boolean decision: True if the given information is a fact according to the given source, else False.")
    rationale: str = Field(description="Your detailed rationale in deciding whether the given information is a fact or not.")


class FactChecker:
    def __init__(self, model_params: dict[str, Any], configuration_module_prefix: str):
        self.model_name = model_params['model']
        self.configuration_module_prefix: Final = configuration_module_prefix
        self.base_llm = init_chat_model(
            model=model_params['model'],
            model_provider=model_params['model_provider'],
            api_key=model_params['api_key'],
            **model_params['model_args']
        )
        self.model_params = model_params

    def run(self, state: SearchState) -> SearchState:
        state.steps.append(Node.FACT_CHECKER)
        json_schema_base = get_schema(state=state)

        if state.iteration == 0:
            notes = state.notes.model_dump() # notes will be dict
            json_schema = json_schema_base['properties']
        else:
            notes = {key: getattr(state.notes, key) for key in state.search_focus}
            json_schema = {key: json_schema_base['properties'][key] for key in state.search_focus}

        FactfulnessModel = create_model('FactfulnessModel', **{x: AtomicFactfulness for x in json_schema.keys()})

        instructions = FACT_CHECK_INSTRUCTIONS.format(search_type=state.search_type,
                                                      info=state.topic,
                                                      notes=json.dumps(notes, indent=2),
                                                      content=state.source_str,
                                                      today=datetime.date.today().isoformat())

        structured_llm = self.base_llm.with_structured_output(
            schema=FactfulnessModel,
            include_raw=True,
        ).with_retry(
            stop_after_attempt=self.model_params['max_llm_retries']
        )

        with get_usage_metadata_callback() as cb:
            out_dict = structured_llm.invoke(instructions)
            fact_check = out_dict['parsed']
            for k in notes.keys():
                if getattr(fact_check, k).is_fact is False:
                    match notes[k]:
                        case str():
                            setattr(state.notes, k, 'Not Available')
                        case list():
                            setattr(state.notes, k, [])

            state.token_usage[self.model_name]['input_tokens'] += cb.usage_metadata[self.model_name]['input_tokens']
            state.token_usage[self.model_name]['output_tokens'] += cb.usage_metadata[self.model_name]['output_tokens']

        return state